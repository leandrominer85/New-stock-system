{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f8574f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9320624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from cleaning_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de355386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "# check if this is the same path used for raw_analysis\n",
    "path = r'C:/Users/jantu/Downloads/stock_system-221209/raw_stock-221206/*'\n",
    "raw_combined = 'raw_combined.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6620b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of files to read from the path\n",
    "files = glob.glob(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618351d6",
   "metadata": {},
   "source": [
    "- Get the file path, the supplier_code (a key in the dictionary below)\n",
    "and the parameters of the dictionary below for each key. It checks the file extension and then uses the appropriate pandas function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc9dded",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "list1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e113afa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def read_file(file, supplier_code, header, special_operation):\n",
    "        # Check if file is xls or xlsx\n",
    "    if \"xlsx\" in file or \"xls\" in file.lower():\n",
    "        df = pd.read_excel(\n",
    "            io = Fr\"{file}\", \n",
    "            header = file_columns[supplier_code][\"header\"], \n",
    "            usecols = file_columns[supplier_code][\"columns\"]\n",
    "            )[file_columns[supplier_code][\"columns\"]] # To maintain parsed columns orders if the dataframe require more special operations like adding blank columns or removing unwanted rows\n",
    "        list1.append(file_columns[supplier_code])\n",
    "        if file_columns[supplier_code][\"special_operation\"]:\n",
    "            df = file_columns[supplier_code][\"special_operation\"](df)\n",
    "\n",
    "        df.columns = [\"Manufacturer\", \"Partnumber\", \"Quantity\", \"Price\"]\n",
    "\n",
    "        df[\"supplier\"] = supplier_code\n",
    "\n",
    "        #Check if file is csv or txt\n",
    "    elif \"csv\" in file.lower() or \"txt\" in file.lower():\n",
    "        df = pd.read_csv(\n",
    "            file, \n",
    "            header = file_columns[supplier_code][\"header\"], \n",
    "            usecols = file_columns[supplier_code][\"columns\"],\n",
    "            sep = \";|\\|\", \n",
    "            encoding = \"ISO-8859-1\", # This encoding is important to work with most of the files\n",
    "            engine = \"python\" # This engine is to accept regex at sep parameter for csv with variety of delimiters\n",
    "            )[file_columns[supplier_code][\"columns\"]] # To maintain parsed columns orders\n",
    "\n",
    "        if file_columns[supplier_code][\"special_operation\"]:\n",
    "            df = file_columns[supplier_code][\"special_operation\"](df)\n",
    "\n",
    "        df.columns = [\"Manufacturer\", \"Partnumber\", \"Quantity\", \"Price\"]\n",
    "\n",
    "        df[\"supplier\"] = supplier_code\n",
    "\n",
    "    else:\n",
    "        print(\"unkown file formate: \", file)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3106f2f",
   "metadata": {},
   "source": [
    "print(\"List1: \", list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfce5c48",
   "metadata": {},
   "source": [
    "Dictionary to pass to the read function. For each file, it needs the header (where the column name is), the columns\n",
    "names and if any special operations is needed (the cleaning_functions functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a79c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_columns = {\n",
    "    \"metal\":    {    \"header\": 0, \n",
    "                    \"columns\": [\"Fabricante\", \"Codigo_fornecedor\", \"quantity\", \"PRECO_LIQUIDO\"],\n",
    "                    \"special_operation\": None\n",
    "                },\n",
    "\n",
    "    \"medauto\":    {    \"header\": 0, \n",
    "                    \"columns\": [\"Fornecedor\", \"NUMERO DA PEÇA\", \"ESTOQUE\", \"PREÇO\"],\n",
    "                    \"special_operation\": None\n",
    "                },\n",
    "    \"lucios\":     {    \"header\": 0, \n",
    "                    \"columns\": [\"Fabricante\", \"Código Lucios\", \"Disponibilidade\", \"Preço\"],\n",
    "                    \"special_operation\": None\n",
    "                },\n",
    "    \"carbwel\":     {    \"header\": 0, \n",
    "                    \"columns\": [\"Fabricante\", \"Código Fabricante\", \"Disponivel\", \"PrcVenda\"],\n",
    "                    \"special_operation\": None\n",
    "                },\n",
    "    \"mte\":     {    \"header\": 0, \n",
    "                    \"columns\": [\"COD MTE\", \"QTD. ESTOQUE\", \"PREÇO\"],\n",
    "                    \"special_operation\": mte_process\n",
    "                },\n",
    "    \"sueyasu\":     {    \"header\": 0, \n",
    "                    \"columns\": [\"NOME DO FABRICANTE\", \"CODIGO DA PEÇA (FABRICANTE)\", \"QUANTIDADE EM ESTOQUE\", \"PREÇO\"],\n",
    "                    \"special_operation\": sueyasu_process\n",
    "                },\n",
    "    \"polipecas\":{    \"header\": 2, \n",
    "                    \"columns\": [\"COD. FORNECEDOR\", \"PREÇO\"],\n",
    "                    \"special_operation\": polipecas_process\n",
    "                },\n",
    "    \"lucios\":{        \"header\": 0, \n",
    "                    \"columns\": [\"Fabricante\", \"Código Fábrica\", \"Disponibilidade\", \"Preço\"],\n",
    "                    \"special_operation\": None\n",
    "                },\n",
    "    \"ima\":{            \"header\": 0, \n",
    "                    \"columns\": [\"Código XML\", \"Estoque\"],\n",
    "                    \"special_operation\": ima_process\n",
    "                },\n",
    "    \"compel\":{        \"header\": 0, \n",
    "                    \"columns\": [\"FABRICANTE\", \"COD FABRICA\", \"DISPONIBILIDADE\", \"PREÇO\"],\n",
    "                    \"special_operation\": compel_process\n",
    "                },\n",
    "    \"rufato\":{        \"header\": None, \n",
    "                    \"columns\": [5, 4, 3, 2],\n",
    "                    \"special_operation\": None\n",
    "                },\n",
    "    \"real\":{        \"header\": 0, \n",
    "                    \"columns\": [\"NOME_FANTASIA\", \"COD_FABRICANTE\", \"QTDE_SPLESTE\", \"PRECO_SPLESTE\"],\n",
    "                    \"special_operation\": None\n",
    "                },\n",
    "    \"jahu\":{        \"header\": 0, \n",
    "                    \"columns\": ['Marca','Cód.Fabricante', 'Preco','Disponivel'],\n",
    "                    \"special_operation\": jahu_process\n",
    "                },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d9778a",
   "metadata": {},
   "source": [
    "Starts with an empty list that is populated with every data from the files list using the read_file function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64659c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = []\n",
    "for file in files:\n",
    "    file_columns_keys = list(file_columns.keys())\n",
    "    for supplier_code in file_columns_keys:\n",
    "        if supplier_code in file.lower():\n",
    "            print(file, \"====\", supplier_code, file_columns[supplier_code][\"header\"])\n",
    "            all_df.append(read_file( #dataframes are added one by one and merged all at once\n",
    "                file, \n",
    "                supplier_code, \n",
    "                header = file_columns[supplier_code][\"header\"], \n",
    "                special_operation = file_columns[supplier_code][\"special_operation\"]))\n",
    "print(list1)\n",
    "print(\"file_columns_keys :\", file_columns_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cdd4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the raw_combined dataframe\n",
    "pd.concat(all_df, ignore_index = True).to_csv(raw_combined)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
