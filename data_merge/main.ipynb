{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f8574f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9320624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from cleaning_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de355386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "# check if this is the same path used for raw_analysis\n",
    "path = '../data/originals/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6620b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of files to read from the path\n",
    "files = glob.glob(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618351d6",
   "metadata": {},
   "source": [
    "- Get the file path, the supplier_code (a key in the dictionary below)\n",
    "and the parameters of the dictionary below for each key. It checks the file extension and then uses the appropriate pandas function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e113afa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "list1 = []\n",
    "def read_file(file, supplier_code, header, special_operation):\n",
    "        # Check if file is xls or xlsx\n",
    "    if \"xlsx\" in file or \"xls\" in file.lower():\n",
    "        df = pd.read_excel(\n",
    "            io = Fr\"{file}\", \n",
    "            header = file_columns[supplier_code][\"header\"], \n",
    "            usecols = file_columns[supplier_code][\"columns\"]\n",
    "            )[file_columns[supplier_code][\"columns\"]] # To maintain parsed columns orders if the dataframe require more special operations like adding blank columns or removing unwanted rows\n",
    "        list1.append(file_columns[supplier_code])\n",
    "        if file_columns[supplier_code][\"special_operation\"]:\n",
    "            df = file_columns[supplier_code][\"special_operation\"](df)\n",
    "\n",
    "        df.columns = [\"Manufacturer\", \"Partnumber\", \"Quantity\", \"Price\"]\n",
    "\n",
    "        df[\"supplier\"] = supplier_code\n",
    "\n",
    "        #Check if file is csv or txt\n",
    "    elif \"csv\" in file.lower() or \"txt\" in file.lower():\n",
    "        df = pd.read_csv(\n",
    "            file, \n",
    "            header = file_columns[supplier_code][\"header\"], \n",
    "            usecols = file_columns[supplier_code][\"columns\"],\n",
    "            sep = \";|\\|\", \n",
    "            encoding = \"ISO-8859-1\", # This encoding is important to work with most of the files\n",
    "            engine = \"python\" # This engine is to accept regex at sep parameter for csv with variety of delimiters\n",
    "            )[file_columns[supplier_code][\"columns\"]] # To maintain parsed columns orders\n",
    "\n",
    "        if file_columns[supplier_code][\"special_operation\"]:\n",
    "            df = file_columns[supplier_code][\"special_operation\"](df)\n",
    "\n",
    "        df.columns = [\"Manufacturer\", \"Partnumber\", \"Quantity\", \"Price\"]\n",
    "\n",
    "        df[\"supplier\"] = supplier_code\n",
    "\n",
    "    else:\n",
    "        print(\"unkown file formate: \", file)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfce5c48",
   "metadata": {},
   "source": [
    "Dictionary to pass to the read function. For each file, it needs the header (where the column name is), the columns\n",
    "names and if any special operations is needed (the cleaning_functions functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58a79c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_columns = {\n",
    "    \"metal\":    {    \"header\": 0, \n",
    "                    \"columns\": [\"Fabricante\", \"Codigo_fornecedor\", \"quantity\", \"PRECO_LIQUIDO\"],\n",
    "                    \"special_operation\": None\n",
    "                },\n",
    "\n",
    "    \"medauto\":    {    \"header\": 0, \n",
    "                    \"columns\": [\"Fornecedor\", \"NUMERO DA PEÇA\", \"ESTOQUE\", \"PREÇO\"],\n",
    "                    \"special_operation\": None\n",
    "                },\n",
    "    \"lucios\":     {    \"header\": 0, \n",
    "                    \"columns\": [\"Fabricante\", \"Código Lucios\", \"Disponibilidade\", \"Preço\"],\n",
    "                    \"special_operation\": None\n",
    "                },\n",
    "    \"carbwel\":     {    \"header\": 0, \n",
    "                    \"columns\": [\"Fabricante\", \"Código Fabricante\", \"Disponivel\", \"PrcVenda\"],\n",
    "                    \"special_operation\": None\n",
    "                },\n",
    "    \"mte\":     {    \"header\": 0, \n",
    "                    \"columns\": [\"COD MTE\", \"QTD. ESTOQUE\", \"PREÇO\"],\n",
    "                    \"special_operation\": mte_process\n",
    "                },\n",
    "    \"sueyasu\":     {    \"header\": 0, \n",
    "                    \"columns\": [\"NOME DO FABRICANTE\", \"CODIGO DA PEÇA (FABRICANTE)\", \"QUANTIDADE EM ESTOQUE\", \"PREÇO\"],\n",
    "                    \"special_operation\": sueyasu_process\n",
    "                },\n",
    "    \"polipecas\":{    \"header\": 2, \n",
    "                    \"columns\": [\"COD. FORNECEDOR\", \"PREÇO\"],\n",
    "                    \"special_operation\": polipecas_process\n",
    "                },\n",
    "    \"lucios\":{        \"header\": 0, \n",
    "                    \"columns\": [\"Fabricante\", \"Código Fábrica\", \"Disponibilidade\", \"Preço\"],\n",
    "                    \"special_operation\": None\n",
    "                },\n",
    "    \"ima\":{            \"header\": 3, \n",
    "                    \"columns\": [\"Código\",\"Preço C/Imp SP\", \"Múltiplos\"],\n",
    "                    \"special_operation\": ima_process\n",
    "                },\n",
    "    \"compel\":{        \"header\": 0, \n",
    "                    \"columns\": [\"FABRICANTE\", \"COD FABRICA\", \"DISPONIBILIDADE\", \"PREÇO\"],\n",
    "                    \"special_operation\": None\n",
    "                },\n",
    "    \"rufato\":{        \"header\": None, \n",
    "                    \"columns\": [5, 4, 3, 2],\n",
    "                    \"special_operation\": None\n",
    "                },\n",
    "    \"real\":{        \"header\": 0, \n",
    "                    \"columns\": [\"CODIGO_INTERNO\", \"COD_FABRICANTE\",\"NOME_FANTASIA\",\"PRODUTO\",\n",
    "                                \"QTDE_EMB\",\"UNIDADE_MEDIDA\",\"QTDE_SPNORTE\",\"PRECO_SPNORTE\",\n",
    "                                \"QTDE_ABC\",\"PRECO_ABC\",\"QTDE_SPLESTE\",\"PRECO_SPLESTE\"],\n",
    "                    \"special_operation\": real_process\n",
    "                },\n",
    "    \"jahu\":{        \"header\": 0, \n",
    "                    \"columns\": ['Marca','Cód.Fabricante', 'Preco','Disponivel',\"Produto\"],\n",
    "                    \"special_operation\": jahu_process\n",
    "                },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d9778a",
   "metadata": {},
   "source": [
    "Starts with an empty list that is populated with every data from the files list using the read_file function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64659c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/originals\\00-Prod_Metal_001.xlsx ==== metal 0\n",
      "../data/originals\\2022-03-01 - Lista de Preços IMA - 03-2022 - GERAL.XLSX ==== ima 3\n",
      "../data/originals\\ARQUIVO-RUFATO-29-11-2022-HR12-00.TXT ==== rufato None\n",
      "../data/originals\\Arquivo_Compel-13-01-23.csv ==== compel 0\n",
      "../data/originals\\Estoque Carbwel 20 10 22 Karhub.xls ==== carbwel 0\n",
      "../data/originals\\Estoque real 29 11.csv ==== real 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eppmi\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "E:\\Dropbox\\Pessoal\\Python\\trabalho\\Upwork\\New-stock-system\\data_merge\\cleaning_functions.py:144: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[col] = df2[col].apply(lambda x: x.replace(',','.'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/originals\\estoque_jahu_20221129.csv ==== jahu 0\n",
      "../data/originals\\medauto_stock_220916.xlsx ==== medauto 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Dropbox\\Pessoal\\Python\\trabalho\\Upwork\\New-stock-system\\data_merge\\cleaning_functions.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[\"Cód.Fabricante\"] = df2[\"Produto\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/originals\\MTE_ESTOQUE_INTERNET-2.XLSX ==== mte 0\n",
      "../data/originals\\polipecas_stock_220919.xlsx ==== polipecas 2\n",
      "../data/originals\\Relatorio-lucios.xls ==== lucios 0\n",
      "WARNING *** file size (3141173) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "../data/originals\\Sueyasu - 27-09-22.xlsx ==== sueyasu 0\n"
     ]
    }
   ],
   "source": [
    "all_df = []\n",
    "for file in files:\n",
    "    file_columns_keys = list(file_columns.keys())\n",
    "    for supplier_code in file_columns_keys:\n",
    "        if supplier_code in file.lower():\n",
    "            print(file, \"====\", supplier_code, file_columns[supplier_code][\"header\"])\n",
    "            all_df.append(read_file( #dataframes are added one by one and merged all at once\n",
    "                file, \n",
    "                supplier_code, \n",
    "                header = file_columns[supplier_code][\"header\"], \n",
    "                special_operation = file_columns[supplier_code][\"special_operation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7cb922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(all_df, ignore_index = True).to_csv(\"../data/merged_database/combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5cdd4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output file in third_etl in the raw_stock folder, naming it with real_third_etl\n",
    "pd.concat(all_df, ignore_index = True).to_csv(\"../data/raw_analysis/real_third_etl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "271d20ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eppmi\\AppData\\Local\\Temp/ipykernel_16848/1044509951.py:2: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  pd.concat(all_df, ignore_index = True).to_csv('../data/text_output/real_third_etl_{}.txt'.format(pd.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")))\n"
     ]
    }
   ],
   "source": [
    "#Save with timestamp\n",
    "pd.concat(all_df, ignore_index = True).to_csv('../data/text_output/real_third_etl_{}.txt'.format(pd.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113fabec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
